schema: '2.0'
stages:
  download_dataset:
    cmd: ( wget https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip
      -O cats_and_dogs_filtered.zip && unzip cats_and_dogs_filtered.zip -d ./data/raw
      && rm cats_and_dogs_filtered.zip ) &> logs/download_dataset.out
    outs:
    - path: ./data/raw
      md5: 174fe7fcb400140a007ac05c36b5bfd4.dir
      size: 68556316
      nfiles: 3001
    - path: logs/download_dataset.out
      md5: f211c659367eb1b32f30b385df5260de
      size: 325690
  split_dataset:
    cmd: python scripts/split_dataset.py &> logs/split_dataset.out
    deps:
    - path: ./data/raw
      md5: 174fe7fcb400140a007ac05c36b5bfd4.dir
      size: 68556316
      nfiles: 3001
    - path: scripts/split_dataset.py
      md5: e99a47b198dee35710b7c745b60e928c
      size: 1277
    params:
      params.yaml:
        data.dataset.val_test_split:
          val: 0.7
          test: 0.3
    outs:
    - path: ./data/dataset/dataset.csv
      md5: 2f6641598b7fc6c8d1dd031a6d595161
      size: 68108
    - path: ./data/dataset/test
      md5: 326353ae0eed20bee508f30419a0ec25.dir
      size: 6815914
      nfiles: 305
    - path: ./data/dataset/train
      md5: 0a1a83aa537b94b2b07eb1503701eca7.dir
      size: 45613376
      nfiles: 2000
    - path: ./data/dataset/val
      md5: d34d9a2762c720f7415020cd9ddabb1e.dir
      size: 16126886
      nfiles: 695
    - path: logs/split_dataset.out
      md5: 6fa4014992ad6a7d326be58d4a2563b4
      size: 2224
  train:
    cmd: python scripts/train.py &> logs/train.out
    deps:
    - path: ./data/dataset/train
      md5: 0a1a83aa537b94b2b07eb1503701eca7.dir
      size: 45613376
      nfiles: 2000
    - path: ./data/dataset/val
      md5: d34d9a2762c720f7415020cd9ddabb1e.dir
      size: 16126886
      nfiles: 695
    - path: scripts/train.py
      md5: 39a6f9242a0e00193e893e26a0e2cd55
      size: 2993
    params:
      params.yaml:
        model:
          backbone: tensorflow.keras.applications.ResNet50
          preprocess_input: tensorflow.keras.applications.resnet50.preprocess_input
        train:
          batch_size: 32
          img_size:
          - 160
          - 160
          learning_rate: 0.0001
          subdir: train
          epochs:
            frozen: 10
            unfrozen: 15
          fine_tune_at: 100
    outs:
    - path: ./data/train/best_weights.h5
      md5: 07512cc95ec05e9cb12b94b6f718f278
      size: 172679472
    - path: ./data/train/model
      md5: 8bde0c2b64bbd6dab1c5f10ffb6909cd.dir
      size: 177268180
      nfiles: 3
    - path: ./data/train/training_metrics
      md5: a3f41d41bef90a6764346198d8090843.dir
      size: 3800
      nfiles: 4
    - path: logs/train.out
      md5: f9eb235c68cf6c01c4c300ae32cca0ce
      size: 276673
  evaluate:
    cmd: python scripts/evaluate.py &> logs/evaluate.out
    deps:
    - path: ./data/dataset/test
      md5: 326353ae0eed20bee508f30419a0ec25.dir
      size: 6815914
      nfiles: 305
    - path: ./data/train/model
      md5: 8bde0c2b64bbd6dab1c5f10ffb6909cd.dir
      size: 177268180
      nfiles: 3
    - path: scripts/evaluate.py
      md5: aada14c8861cb28746abb5aa78e9c4c3
      size: 1377
    outs:
    - path: ./data/evaluation/metrics.json
      md5: 5ba98eca1d691aa800be75ffd1aa7ea0
      size: 55
    - path: ./data/evaluation/predictions.csv
      md5: 647eda4ac3f3c93eede738d95f03212e
      size: 21261
    - path: logs/evaluate.out
      md5: 725d714bbcd0ee3fc44d411dfab45fd2
      size: 4839
