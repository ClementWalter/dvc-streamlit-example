schema: '2.0'
stages:
  download_dataset:
    cmd: ( wget https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip
      -O cats_and_dogs_filtered.zip && unzip cats_and_dogs_filtered.zip -d ./data/raw
      && rm cats_and_dogs_filtered.zip ) &> logs/download_dataset.out
    outs:
    - path: ./data/raw
      md5: 174fe7fcb400140a007ac05c36b5bfd4.dir
      size: 68556316
      nfiles: 3001
    - path: logs/download_dataset.out
      md5: f211c659367eb1b32f30b385df5260de
      size: 325690
  split_dataset:
    cmd: python scripts/split_dataset.py &> logs/split_dataset.out
    deps:
    - path: ./data/raw
      md5: 174fe7fcb400140a007ac05c36b5bfd4.dir
      size: 68556316
      nfiles: 3001
    - path: scripts/split_dataset.py
      md5: e99a47b198dee35710b7c745b60e928c
      size: 1277
    params:
      params.yaml:
        data.dataset.val_test_split:
          val: 0.7
          test: 0.3
    outs:
    - path: ./data/dataset/dataset.csv
      md5: 2f6641598b7fc6c8d1dd031a6d595161
      size: 68108
    - path: ./data/dataset/test
      md5: 326353ae0eed20bee508f30419a0ec25.dir
      size: 6815914
      nfiles: 305
    - path: ./data/dataset/train
      md5: 0a1a83aa537b94b2b07eb1503701eca7.dir
      size: 45613376
      nfiles: 2000
    - path: ./data/dataset/val
      md5: d34d9a2762c720f7415020cd9ddabb1e.dir
      size: 16126886
      nfiles: 695
    - path: logs/split_dataset.out
      md5: 6fa4014992ad6a7d326be58d4a2563b4
      size: 2224
  train:
    cmd: python scripts/train.py &> logs/train.out
    deps:
    - path: ./data/dataset/train
      md5: 0a1a83aa537b94b2b07eb1503701eca7.dir
      size: 45613376
      nfiles: 2000
    - path: ./data/dataset/val
      md5: d34d9a2762c720f7415020cd9ddabb1e.dir
      size: 16126886
      nfiles: 695
    - path: scripts/train.py
      md5: a6edfb77adf3b631391890188d246d2c
      size: 3264
    params:
      params.yaml:
        model:
          backbone: tensorflow.keras.applications.ResNet50
          preprocess_input: tensorflow.keras.applications.resnet50.preprocess_input
        train:
          batch_size: 32
          img_size:
          - 160
          - 160
          learning_rate: 0.0001
          subdir: train
          epochs:
            frozen: 10
            unfrozen: 15
          fine_tune_at: 100
    outs:
    - path: ./data/train/best_weights.h5
      md5: d8adc1a3678ae740ac214f352d48a05e
      size: 172679472
    - path: ./data/train/model
      md5: f620686421a581af909b576489fe2abb.dir
      size: 177275013
      nfiles: 3
    - path: ./data/train/training_metrics
      md5: d74d74a16fe3c4a5424441503827213e.dir
      size: 3810
      nfiles: 4
    - path: logs/train.out
      md5: 37770d8d49a959d4343bbf82906848da
      size: 276679
  evaluate:
    cmd: python scripts/evaluate.py &> logs/evaluate.out
    deps:
    - path: ./data/dataset/test
      md5: 326353ae0eed20bee508f30419a0ec25.dir
      size: 6815914
      nfiles: 305
    - path: ./data/train/model
      md5: f620686421a581af909b576489fe2abb.dir
      size: 177275013
      nfiles: 3
    - path: scripts/evaluate.py
      md5: aada14c8861cb28746abb5aa78e9c4c3
      size: 1377
    outs:
    - path: ./data/evaluation/metrics.json
      md5: 5ba98eca1d691aa800be75ffd1aa7ea0
      size: 55
    - path: ./data/evaluation/predictions.csv
      md5: e140a05dde76c4c47af03c63103762b5
      size: 21512
    - path: logs/evaluate.out
      md5: ec5490a55b5a6b528dccfbd1b2eb81f4
      size: 4839
